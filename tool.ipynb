{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMkUwtCnYG56mclnnO1lgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song20011219/song/blob/main/tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s4Fqh9I-Zhy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.utils as utils\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def get_label_and_pred(model, dataloader, device):\n",
        "    all_label = []\n",
        "    all_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader):\n",
        "            # get the inputs and labels\n",
        "            inputs, labels = data['data'].to(device), data['label'].to(device)\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            if isinstance(outputs, list):\n",
        "                outputs = outputs[0]\n",
        "            # collect labels & prediction\n",
        "            prediction = torch.max(outputs, 1)[1]\n",
        "            all_label.extend(labels.squeeze())\n",
        "            all_pred.extend(prediction)\n",
        "    # Compute accuracy\n",
        "    all_label = torch.stack(all_label, dim=0)\n",
        "    all_pred = torch.stack(all_pred, dim=0)\n",
        "    all_label = all_label.squeeze().cpu().data.squeeze().numpy()\n",
        "    all_pred = all_pred.cpu().data.squeeze().numpy()\n",
        "    return all_label, all_pred\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(model, dataloader, device, save_path='confmat.png', normalize=True):\n",
        "    # Get prediction\n",
        "    all_label, all_pred = get_label_and_pred(model, dataloader, device)\n",
        "    confmat = confusion_matrix(all_label, all_pred)\n",
        "\n",
        "    # Normalize the matrix\n",
        "    if normalize:\n",
        "        confmat = confmat.astype('float') / confmat.sum(axis=1)[:, np.newaxis]\n",
        "    # Draw matrix\n",
        "    plt.figure(figsize=(20,20))\n",
        "    # confmat = np.random.rand(100,100)\n",
        "    plt.imshow(confmat, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.colorbar()\n",
        "    # Add ticks\n",
        "    ticks = np.arange(100)\n",
        "    plt.xticks(ticks, fontsize=8)\n",
        "    plt.yticks(ticks, fontsize=8)\n",
        "    plt.grid(True)\n",
        "    # Add title & labels\n",
        "    plt.title('Confusion matrix', fontsize=20)\n",
        "    plt.xlabel('Predicted label', fontsize=20)\n",
        "    plt.ylabel('True label', fontsize=20)\n",
        "    # Save figure\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    # Ranking\n",
        "    sorted_index = np.diag(confmat).argsort()\n",
        "    for i in range(10):\n",
        "        # print(type(sorted_index[i]))\n",
        "        print(test_set.label_to_word(int(sorted_index[i])), confmat[sorted_index[i]][sorted_index[i]])\n",
        "    # Save to csv\n",
        "    np.savetxt('matrix.csv', confmat, delimiter=',')\n",
        "\n",
        "\n",
        "def visualize_attn(I, c):\n",
        "    # Image\n",
        "    img = I.permute((1,2,0)).cpu().numpy()\n",
        "    # Heatmap\n",
        "    N, C, H, W = c.size()\n",
        "    a = F.softmax(c.view(N,C,-1), dim=2).view(N,C,H,W)\n",
        "    up_factor = 128/H\n",
        "    # print(up_factor, I.size(), c.size())\n",
        "    if up_factor > 1:\n",
        "        a = F.interpolate(a, scale_factor=up_factor, mode='bilinear', align_corners=False)\n",
        "    attn = utils.make_grid(a, nrow=4, normalize=True, scale_each=True)\n",
        "    attn = attn.permute((1,2,0)).mul(255).byte().cpu().numpy()\n",
        "    attn = cv2.applyColorMap(attn, cv2.COLORMAP_JET)\n",
        "    attn = cv2.cvtColor(attn, cv2.COLOR_BGR2RGB)\n",
        "    # Add the heatmap to the image\n",
        "    vis = 0.6 * img + 0.4 * attn\n",
        "    return torch.from_numpy(vis).permute(2,0,1)\n",
        "\n",
        "\n",
        "def plot_attention_map(model, dataloader, device):\n",
        "    # Summary writer\n",
        "    writer = SummaryWriter(\"runs/attention_{:%Y-%m-%d_%H-%M-%S}\".format(datetime.now()))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(dataloader):\n",
        "            # get images\n",
        "            inputs = data['data'].to(device)\n",
        "            if batch_idx == 0:\n",
        "                images = inputs[0:16,:,:,:,:]\n",
        "                I = utils.make_grid(images[:,:,0,:,:], nrow=4, normalize=True, scale_each=True)\n",
        "                writer.add_image('origin', I)\n",
        "                _, c1, c2, c3, c4 = model(images)\n",
        "                # print(I.shape, c1.shape, c2.shape, c3.shape, c4.shape)\n",
        "                attn1 = visualize_attn(I, c1[:,:,0,:,:])\n",
        "                writer.add_image('attn1', attn1)\n",
        "                attn2 = visualize_attn(I, c2[:,:,0,:,:])\n",
        "                writer.add_image('attn2', attn2)\n",
        "                attn3 = visualize_attn(I, c3[:,:,0,:,:])\n",
        "                writer.add_image('attn3', attn3)\n",
        "                attn4 = visualize_attn(I, c4[:,:,0,:,:])\n",
        "                writer.add_image('attn4', attn4)\n",
        "                break\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Calculate Word Error Rate\n",
        "Word Error Rate = (Substitutions + Insertions + Deletions) / Number of Words Spoken\n",
        "Reference:\n",
        "https://holianh.github.io/portfolio/Cach-tinh-WER/\n",
        "https://github.com/imalic3/python-word-error-rate\n",
        "\"\"\"\n",
        "def wer(r, h):\n",
        "    # initialisation\n",
        "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion = d[i][j-1] + 1\n",
        "                deletion = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "\n",
        "    return float(d[len(r)][len(h)]) / len(r) * 100\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Calculate WER\n",
        "    r = [1,2,3,4]\n",
        "    h = [1,1,3,5,6]\n",
        "    print(wer(r, h))"
      ]
    }
  ]
}