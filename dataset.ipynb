{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XVno7xq6HJXtnl2EXnMFWA1VOb_UaQe_",
      "authorship_tag": "ABX9TyNgZqEK+mklJJSeGgtD8EqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song20011219/song/blob/main/dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**dataset**"
      ],
      "metadata": {
        "id": "oxjrhZ0bMuyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ASD_Isolated(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        super(ASD_Isolated, self).__init__()\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.frames = 30  # 每个视频样本的帧数\n",
        "        self.data_info = self._get_data_info()\n",
        "\n",
        "    def _get_data_info(self):\n",
        "        data_info = []\n",
        "        for label in (\"arm_flapping\", \"hand_flapping\"):\n",
        "            label_path = os.path.join(self.data_path, label)\n",
        "            for video_folder in os.listdir(label_path):\n",
        "                video_folder_path = os.path.join(label_path, video_folder)\n",
        "                if os.path.isdir(video_folder_path):\n",
        "                    data_info.append((video_folder_path, label))\n",
        "        return data_info\n",
        "\n",
        "    def read_images(self, folder_path):\n",
        "        image_files = sorted([os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.jpg')])\n",
        "        assert len(image_files) == self.frames, f\"Expected {self.frames} images, but found {len(image_files)} in folder {folder_path}\"\n",
        "        images = [Image.open(file) for file in image_files]\n",
        "        if self.transform is not None:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        images = torch.stack(images, dim=0)\n",
        "        images = images.permute(1, 0, 2, 3)  # Adjust dimensions for CNN\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_path, label = self.data_info[idx]\n",
        "        images = self.read_images(folder_path)\n",
        "        label_tensor = torch.tensor(0 if label == \"arm_flapping\" else 1, dtype=torch.long)\n",
        "        return {'data': images, 'label': label_tensor}\n",
        "\n",
        "# 测试\n",
        "if __name__ == '__main__':\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize([128, 128]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    dataset = ASD_Isolated(data_path=\"/content/drive/MyDrive/output_frames\", transform=transform)\n",
        "    print(f\"Dataset size: {len(dataset)}\")\n",
        "    sample = dataset[0]\n",
        "    print(f\"Sample image shape: {sample['data'].shape}, Label: {sample['label']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw65jjqaCK4a",
        "outputId": "754bf32b-1da9-4fcc-e7f0-6d8ee043028d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 163\n",
            "Sample image shape: torch.Size([3, 30, 128, 128]), Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train**"
      ],
      "metadata": {
        "id": "RmhRN72VQfRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入所需的库\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.transforms as transforms\n",
        "from models.Conv3D import CNN3D, resnet18, resnet34, resnet50, resnet101, r2plus1d_18\n",
        "from dataset import ASD_Isolated\n",
        "from train import train_epoch\n",
        "from validation import val_epoch\n",
        "\n",
        "# 路径设置\n",
        "data_path = \"YOUR_DATASET_PATH\"  # 你将填写数据集路径\n",
        "label_path = \"YOUR_LABEL_PATH\"  # 你将填写标签文件路径\n",
        "model_path = \"/home/haodong/Data/cnn3d_models\"\n",
        "log_path = \"log/cnn3d_{:%Y-%m-%d_%H-%M-%S}.log\".format(datetime.now())\n",
        "sum_path = \"runs/slr_cnn3d_{:%Y-%m-%d_%H-%M-%S}\".format(datetime.now())\n",
        "\n",
        "# 日志文件和Tensorboard writer的设置\n",
        "logging.basicConfig(level=logging.INFO, format='%(message)s', handlers=[logging.FileHandler(log_path), logging.StreamHandler()])\n",
        "logger = logging.getLogger('SLR')\n",
        "logger.info('Logging to file...')\n",
        "writer = SummaryWriter(sum_path)\n",
        "\n",
        "# 设置特定的GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
        "# 设备设置\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 超参数设置\n",
        "num_classes = 2\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "learning_rate = 1e-5\n",
        "log_interval = 20\n",
        "sample_size = 128\n",
        "sample_duration = 30\n",
        "attention = False\n",
        "drop_p = 0.0\n",
        "hidden1, hidden2 = 512, 256\n",
        "\n",
        "# 使用3DCNN进行训练\n",
        "if __name__ == '__main__':\n",
        "    # Load data\n",
        "    # 注意：这里需要替换为处理ASD数据集的自定义数据加载器\n",
        "    train_set = ASD_Isolated(data_path=data_path, label_path=label_path, frames=sample_duration,\n",
        "        num_classes=num_classes, train=True, transform=transform)\n",
        "    val_set = ASD_Isolated(data_path=data_path, label_path=label_path, frames=sample_duration,\n",
        "        num_classes=num_classes, train=False, transform=transform)\n",
        "    logger.info(\"数据集样本数: {}\".format(len(train_set)+len(val_set)))\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
        "    # 创建模型\n",
        "    # model = CNN3D(sample_size=sample_size, sample_duration=sample_duration, drop_p=drop_p,\n",
        "    #             hidden1=hidden1, hidden2=hidden2, num_classes=num_classes).to(device)\n",
        "    model = resnet18(pretrained=True, progress=True, sample_size=sample_size, sample_duration=sample_duration,\n",
        "                    attention=attention, num_classes=num_classes).to(device)\n",
        "    # model = r2plus1d_18(pretrained=True, num_classes=num_classes).to(device)\n",
        "    # 并行运行模型\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        logger.info(\"使用{}个GPU\".format(torch.cuda.device_count()))\n",
        "        model = nn.DataParallel(model)\n",
        "    # 创建损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # 开始训练\n",
        "    logger.info(\"开始训练\".center(60, '#'))\n",
        "    for epoch in range(epochs):\n",
        "        # 训练模型\n",
        "        train_epoch(model, criterion, optimizer, train_loader, device, epoch, logger, log_interval, writer)\n",
        "\n",
        "        # 验证模型\n",
        "        val_epoch(model, criterion, val_loader, device, epoch, logger, writer)\n",
        "\n",
        "        # 保存模型\n",
        "        torch.save(model.state_dict(), os.path.join(model_path, \"slr_cnn3d_epoch{:03d}.pth\".format(epoch+1)))\n",
        "        logger.info(\"第{}轮训练完成的模型已保存\".format(epoch+1).center(60, '#'))\n",
        "\n",
        "    logger.info(\"训练完成\".center(60, '#'))\n"
      ],
      "metadata": {
        "id": "y6KYCTVKbvWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie3yOUZSEsEI",
        "outputId": "faaa781a-2a8a-42c3-af3e-2271fece96c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**test**"
      ],
      "metadata": {
        "id": "WV248djQOjCf"
      }
    }
  ]
}